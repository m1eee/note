摘要——音频DeepFake是通过深度神经网络生成的语音片段。由于其可能被用于假新闻、冒充身份或敲诈勒索，具有极大的误导性并构成威胁。在本研究中，我们通过提出SpecRNet，一种具有快速推理时间和低计算需求的神经网络架构，致力于提高音频DeepFake检测方法的可用性。我们的基准测试表明，SpecRNet在处理音频样本时所需时间减少了约40%，其性能可与LCNN架构——当前最优的音频DeepFake检测模型之一——相媲美。此方法不仅可被在线多媒体服务用于验证每日上传的大量内容，还可由于其低需求特性，被普通用户在其设备上用来评估素材。此外，我们在三个独特场景下进行了基准测试，进一步验证了模型的正确性。这些场景包括低资源数据集检测、短语音片段检测以及有限攻击基准测试，后者重点分析了特定攻击对不同架构的影响。
关键词——DeepFake检测、语音处理、神经网络、深度学习



## I. 引言

DeepFake是指一类用于操控视听内容的算法。这些算法利用深度神经网络，生成极具迷惑性的生物特征伪造内容，例如面部或语音。DeepFake技术是自动生成或修改原始视听内容最流行的方法之一。其最初的方法于2017年被引入，可以生成一种视频，将原始个体的面部与另一个人的面部进行交换。这种现象在音频领域同样存在。“音频DeepFake”一词涵盖了能够人工修改语音的解决方案。这些方法可以通过文本转语音（Text-To-Speech，TTS）[1]–[3]和语音克隆（Voice Cloning）[4]、[5]生成新的语音，或者通过语音转换（Voice Conversion）[6]、[7]对现有语音进行修改，从而将其更改为他人的声音。近年来的架构不仅可以生成语音，还注重正确的语调、重音和节奏。这样的篡改材料质量很高，并具有很强的迷惑性。相比真实语音，DeepFake语音通常能获得较高的主观意见评分（MOS）。

DeepFake在许多恶意场景中被广泛使用，并对生活的各个领域造成了威胁。假新闻是最突出且最危险的例子之一，例如通过伪造政治人物的发言来引发冲突。篡改的样本还可用于绕过扬声器识别（身份认证）系统（例如银行系统中的语音识别），这类系统由于相关法规的推动正日益普及[8]。此外，基于DeepFake的身份冒充还被用于敲诈勒索[9]。

创建音频DeepFake的过程非常简单——目前已有许多文档齐全的开源工具包，这些工具仅需要一台消费级电脑即可。此外，实时语音克隆（Real Time Voice Cloning，RTVC）[4]等方法仅需几秒钟的语音信号就能生成语音克隆片段。尽管其结果的复杂性不如基于数小时源材料、使用最先进方法生成的DeepFake，但结合低质量的互联网连接及其他降低音质的因素时，这些结果仍足以欺骗他人，从而使篡改更难被发现。



### 音频DeepFake检测问题

音频欺骗（Audio Spoofing）是语音处理领域中的一个问题，与DeepFake概念相似。它包括语音合成、语音转换以及重放攻击的问题。DeepFake和音频欺骗的主要区别在于目标不同：DeepFake主要用于欺骗人类，使其相信伪造语音是真实的，而音频欺骗则旨在欺骗自动语音验证系统，使其误认为被验证的个体是目标声音的所有者。此外，DeepFake总是生成新的内容，而音频欺骗可以通过现有的样本创建，例如重放或合并不同的音频片段。

近年来，DeepFake技术因其不断进步的算法、日益普及和易用性而引发了研究社区的广泛关注。科学家们开始探索如何区分原始语音和生成语音的方法。现有的解决方案在分类方法（如高斯混合模型（GMMs）[10]或深度神经网络[11]-[14]）以及所使用的音频表示形式上均有所不同。

我们的主要研究动机是减少音频DeepFake检测的计算需求和推理时间。为此，我们提出了一种新的基于频谱图的模型SpecRNet，其设计灵感来自RawNet2 [14]。轻量化架构可以广泛应用于快速筛查可疑样本的问题上。

### DeepFake问题的规模化考量

DeepFake问题需要从规模化的角度进行考量。因DeepFake可能涉及大量数据，因此可将其视为大数据任务。随着如欧盟《虚假信息加强行为准则》[15]等法规的引入，内容提供商和托管平台需实施自我监管标准以应对虚假信息（包括DeepFake）。未来的DeepFake检测研究需着眼于降低计算复杂度，同时保持高检测性能。

在应用方面，在线多媒体平台是最自然的场景，这些平台每天上传的视频内容高达72万小时[16]。轻量化的检测方法可有效发现潜在的伪造材料。此外，这些方法也使普通用户能够检测伪造材料——通过降低计算和内存需求，使其在无需GPU支持的情况下即可运行检测方法。

值得注意的是，由于普通用户面临的伪造内容往往较为简单（因此欺骗性较低），即便是较小的模型，在不达到最先进性能的情况下，仍足以检测此类篡改内容。这些话题在此前的研究中已有探讨[17]-[19]。

### 本研究的贡献

我们的研究贡献包括以下几个方面：

1. 提出了新的神经网络架构——SpecRNet。
2. 比较了SpecRNet与其设计灵感RawNet2 [14]以及当前顶尖的音频DeepFake检测架构LCNN [11]在WaveFake数据集上的性能。
3. 分别在CPU和GPU上评估了不同批量大小的推理时间。
4. 在三种独特的场景下进行了评估：数据稀缺、有限攻击和短语音片段。



##  II.相关工作

音频DeepFake检测相较于视觉DeepFake检测是一个更新的任务。因此，音频相关的数据集和检测方法相对较少。ASVspoof [20]是检测伪造音频领域中最重要的挑战之一。在2021年的双年赛中，新增了语音DeepFake（DF）子集，与逻辑访问（LA）和物理访问（PA）子集一起发布。然而，该子集在本文撰写时尚不可用。

FakeAVCeleb [13]是一个多模态数据集的例子，其中样本同时包括视觉和音频的篡改。然而，其音频部分仅采用RTVC [4]生成，生成样本的多样性较低，因此未被选作我们的评估子集。WaveFake [21]是迄今为止最大的音频DeepFake检测数据集，包含约12万个样本，样本由8种伪造方法生成。凭借其数据量、支持的语言（英语和日语）以及多样的生成方法，成为我们选择的基准数据集。

尽管音频DeepFake检测知名度低于视觉DeepFake检测，但其作为真实性验证的分支正不断增长。由于音频DeepFake与音频欺骗相似，一些音频欺骗检测方法也被改编用于该领域。检测方法可以分为经典方法和基于深度学习的方法。例如，高斯混合模型（GMM）[10]是经典方法的代表。然而，目前大多数方法基于深度学习（DL），因为经典方法如GMM需要针对每种攻击类型单独建模，降低了其可扩展性和灵活性。

基于DL的方法根据使用的音频表示形式进一步划分。某些方法（如[14]、[22]）直接处理原始信号信息，而其他方法（如[11]、[12]、[23]）则基于频谱图表示的音频形式（前端）。常见的表示方法包括梅尔频率倒谱系数（MFCCs）和线性频率倒谱系数（LFCCs）。此外，基于频谱图特征的视觉DeepFake检测方法也已被改编用于音频DeepFake检测[13]。

## III. SpecRNet

在本节中，我们提出了一个新颖的架构——**SpecRNet**。其骨干网络设计灵感来源于**RawNet2** [14]。与前者不同的是，RawNet2处理的是一维原始音频信号，而SpecRNet处理的是二维频谱图信息，特别是**线性频率倒谱系数（LFCC）**。这一选择基于近期研究表明，基于频谱图的模型在性能上明显优于基于原始信号的架构 [21]。

#### 模型结构

SpecRNet的输入为音频信号的LFCC表示，其处理流程如下：

1. 输入数据首先通过**二维批归一化**（Batch Normalization）[24]，然后应用**SeLU激活函数**。

2. 模型由3个残差块（Residual Block）组成，每个块包含2个卷积层，卷积层之前有批归一化和LeakyReLU激活函数

   - 第一块残差块的输入不进行额外的归一化和激活处理，因为输入已经被前面的批归一化和SeLU处理过。
   - 在残差路径中，使用了一个额外的卷积层（核大小为1），以同步主路径和残差路径的通道数。第三块残差块中通道数固定为64，因此无需额外卷积层。
   
3. 每个残差块后依次连接：

   - **二维最大池化层**；
   - **FMS注意力块（FMS Attention Block）** [25]；
   - 再次应用二维最大池化层。

残差块和FMS注意力层的前向传播流程如图1所示。

1. 模型的最后部分包括两层**双向GRU层** [26]和两层全连接层。模型最终输出为一个范围在[0, 1]之间的单一值，通过阈值判
1. 断输入是伪造样本还是正常样本（bona fide）。详细的架构参数见**表I**。

我们提供了基于PyTorch的实现，代码已公开于GitHub:
 https://github.com/piotrkawa/specrnet



## IV. 基准测试——完整数据集

为了评估SpecRNet的性能，我们使用**WaveFake数据集** [21]进行了基准测试。实现基于数据集作者提供的代码库。我们将SpecRNet与两个领先的最先进架构进行了比较，分别是**LCNN**和**RawNet2**。

#### 对比模型

- **LCNN**：基于频谱图信息的分析方法。
- **RawNet2**：基于原始音频信号分析的方法。
   这两种架构均是音频DeepFake检测任务中的主流方法，通常也用于音频欺骗检测任务。

#### 数据集

基准测试中使用的数据集由以下组成：

- 104,885个伪造样本（fake）和13,100个真实样本（bona fide）。

- 真实语音

  来自两个数据集：

  - **LJSpeech**（英语）[27]
  - **JSUT**（日语）[28]

伪造语音由以下8种音频生成方法创建：

1. **WaveGlow** [29]
2. **Multi-band MelGAN** 和 **Full-band MelGAN** [30]
3. **MelGAN** 和 **MelGAN Large** [31]
4. **HiFi-GAN** [32]
5. **ParallelWaveGAN** [33]（结合TTS管道）

一些方法是其他方法的改进或变种，例如：

- TTS管道基于Conformer [34]，随后微调了PWG。
- MelGAN Large相较于MelGAN具有更大的感受野。
- Full-band和Multi-band MelGAN在计算损失时使用了不同的策略。

所有样本均经过WaveFake的预处理流程：

1. 采样率被调整为**16kHz单声道**；
2. 去除了**超过0.2秒的静音片段**；
3. 样本长度标准化为**约4秒**，通过裁剪或填充（重复样本）实现；
4. 进行了**过采样**处理，以确保两类样本（bona fide vs. fake）之间的平衡。

#### B. 训练过程

每个分类器训练了10个epoch——每个epoch结束时在测试集上进行验证。选择在验证集上表现最好的检查点用于最终的评估集测试。我们遵循WaveFake论文中的命名约定，分别用train、test和eval表示训练集、测试集和评估集。每个子集——训练集、测试集和评估集都包含每种攻击类型的数据，数据划分比例为70:15:15。为了确保结果的可复现性并具有良好的泛化能力，每种架构都使用3个不同的随机种子进行训练和测试。这也适用于所有剩余的基准测试。

训练基于Adam优化器[35]，批量大小为128个样本。我们使用二元交叉熵损失函数。所有模型均使用10^-4的学习率，这是RawNet2和LCNN论文中报告的原始值。RawNet2和SpecRNet还额外使用了值为10^-4的权重衰减进行正则化。

如前所述，各模型在处理数据表示上有所不同。RawNet2使用的是原始音频信号，而LCNN和SpecRNet基于频谱图的前端处理，即LFCC。这些频谱图是基于FakeAVCeleb作者[13]使用的参数创建的：25ms的Hann窗、10ms的窗移、512点的FFT以及80个LFCC特征。这导致了一个二维特征，大小为80×N（N为帧数）。

我们将比较基于两个指标——等错误率（EER）和接收者操作特征曲线下面积（AUC）。等错误率（EER）通常用于生物测量学、DeepFake检测和反欺骗任务中。特别地，我们以百分比形式展示EER。接收者操作特征（ROC）曲线的曲线下面积（AUC）是一个反映统计匹配能力的指标，通常用于二分类任务。此外，它考虑了所有可能的阈值并显示了它们对最终结果的影响。

#### C. 实验结果

表II包含了在WaveFake数据集上训练的LCNN、RawNet2和SpecRNet架构的评估结果。LCNN在两个指标上均提供了最佳结果——EER为0.1399，AUC为99.9952。SpecRNet表现接近，EER为0.1549，AUC为99.9941。值得一提的是，SpecRNet的结果更为一致（以较小的标准差为特征），这是选择DeepFake检测模型的关键因素之一。RawNet2表现最差，EER为4.5973，AUC为99.1254。这些结果表明，在DeepFake检测任务中，基于LFCC的方法比基于原始信号的架构表现更好。

#### D. 时间与复杂度对比

除了评估性能，我们还测量了模型的复杂度。表III展示了每种架构的可训练参数数量。SpecRNet的参数数量几乎是LCNN的一半，约为RawNet2的1/60。这有助于更快的推理时间以及更低的内存需求。除了计算参数数量，我们还测量了模型在随机样本上的推理时间。我们报告了在1,000次推理中的平均结果。为了涵盖不同的使用场景，我们在两种类型的设备上进行了基准测试——GPU（NVIDIA Tesla P40）和CPU（2 GHz四核Intel Core i5）。我们以不同的批量大小报告了时间，因为这对应于验证完整素材的速度。通过将语音片段分成连续的音频块，可以用作批量输入，整个素材可通过单次前向传递进行分析。

表IV中显示的值（针对GPU和CPU情况）表明，较大的批量大小会导致推理时间的显著差异。当批量大小为单个样本时，LCNN和SpecRNet之间的差异可以忽略不计；但当样本量为16或32时，差异显著增大。RawNet2的推理时间最高——大约是SpecRNet的6倍。尽管RawNet2操作于原始波形且无需额外计算，但LCNN和SpecRNet基于LFCC前端，这需要在使用网络输入之前进行额外计算。计算时间对两种模型来说是相同的，在GPU上的时间分别为0.9779ms（批量大小为1）、7.2666ms（批量大小为16）和13.6549ms（批量大小为32），这仍使这些解决方案比RawNet2显著更快。同样的原则适用于CPU计算。总体结果表明，SpecRNet在GPU上分析2分钟的素材仅需约13ms。这种效率表明，该模型可以成功地用于分析上传到在线多媒体平台的大数据环境。我们的DeepFake检测模型可以在音频上传期间在处理缓冲区上运行，允许在样本被更广泛地公开之前实现近乎实时的验证。

## V. 基准测试——有限攻击

以下部分包含关于我们基准测试的信息，该测试探索了各种DeepFake操作（攻击）如何影响最终模型的性能。我们在每次训练中省略一种可用的攻击，即训练、测试和评估过程分别进行了8次——每次都没有其中一种操作。比较包括在完整数据集上获得的结果。

这种有限攻击设置可以提供关于特定攻击与所研究方法有效性之间关系的信息。呈现的结果可以解释如下：高EER值表明某种攻击在基线场景中被正确检测（可认为是“易于检测的攻击”），并且在有限攻击场景中其缺失会降低性能。同样地，较低的EER值表明某种攻击较难检测，其在有限攻击场景中的缺失会提高结果，即该攻击在完整数据集中对性能产生了负面影响。在这种情况下，可以选择训练一个专门方法，正确（并高效）识别这种攻击；当检测到这种攻击时，专门方法的结果将覆盖通用的DeepFake检测模型。

这种设置与[21]中提出的分布外方法类似。虽然训练过程是类似的（忽略某种攻击），但二者在评估过程上有所不同——WaveFake的基准测试在剩余的攻击上也进行了评估。该场景的主要思想是评估泛化能力，而我们的基准测试侧重于评估特定攻击对给定模型的难度。本基准测试与第IV节中描述的基准测试在训练、测试和评估过程中使用的攻击以及评估的模型上有所不同。设置仅涉及两个基于频谱图的模型：LCNN和SpecRNet，因为它们的性能优于基于原始音频的RawNet2。

表V 包含有限攻击基准测试中的结果。结果显示了数据集中不同攻击对结果的影响——有些攻击提高了性能，而有些则导致性能下降。从LCNN的表现可以看出，MelGAN是对该分类器来说最难处理的攻击——在去除该攻击后，EER从完整数据集的0.1399降低至0.0871。相反，在省略MelGAN-Large时，EER达到了最差值0.1483。有趣的是，MelGAN-Large是唯一一个对指标产生正面影响的攻击。
 对SpecRNet而言，MelGAN同样是最难的攻击——它的存在使EER从0.1549降至0.1361。而去除Parallel WaveGAN导致EER达到了最高值0.1804，表明这些样本在基线场景中平均表现最好。

AUC指标在所有评估场景中表现出相似的结果——均超过99.99%。LCNN的最佳和最差结果之间的相对差异为0.0042%，而SpecRNet为0.0045%。对于LCNN，在省略Hifi-GAN时达到了最高的AUC（99.9994），而完整数据集的AUC为99.9952。同样，SpecRNet的基线AUC为99.9941，而省略MelGAN后的AUC为99.9987。由于篇幅限制，完整表格未列出。

MelGAN和MelGAN-Large（MelGAN的大接收场版本）的结果存在显著差异。我们认为，MelGAN-Large的更大架构导致其生成更多的伪造特征（即用于区分真实与伪造样本的特征）。

我们的模型性能稳定，接近于LCNN。在所有场景中，没有一个分类器仅学会区分某一种攻击而忽略其他操作——所有攻击均被考虑在内。值得一提的是，SpecRNet在不同攻击省略场景中的EER标准差（Std）较低（0.0149），而LCNN为0.0189。这表明我们的架构具有更好的泛化能力，在面对新的攻击方法时能提供更稳定的性能。

## VI. 基准测试——短语音片段

语音片段的有效性受多种因素影响，可以分为技术因素（如操作方法的质量，如音素映射或语音合成质量）和环境因素（如交通噪声或电话通话中的失真）。语音片段的时长是另一个关键因素——包含多个单词（甚至句子）的较长样本往往更容易暴露不一致性或人为痕迹，例如语调、发音或突然的频率/音调变化。

在此基准测试中，我们评估了网络在短语音序列上的有效性。这种设置反映了一种场景，即对手不生成整段语音，而是替换句子中的关键词。这种方式使得语音片段保持了原始的自然性，同时却可以传达不同的内容（如，将批评对手的内容变为抨击盟友）。

该基准测试与第IV节中的基准测试的主要区别在于样本的时长——所有子集中的语音被修剪为1秒（而非默认的4秒）。需要注意的是，较短的样本更难被识别为DeepFake，但1秒足以识别关键词，例如在说话人身份验证中提到的密码，或者在生成假新闻时出现的重要短语。此外，我们确保所有样本都包含语音，通过在预处理阶段剪去静音来实现。

表VI显示，所有架构在短语音片段上表现较差。LCNN在EER和AUC上分别为0.9955和99.9486，与基线测试最为接近。而SpecRNet的性能下降更显著，EER为1.1781，AUC为99.9322。RawNet2表现最差，EER达到了14.4499，AUC为93.4013。性能下降的主要原因在于分类器处理的数据量减少至原来的1/4，这导致区分真实与伪造样本的伪造特征数量减少。尽管如此，基于频谱图的方法依然表现出足够的鲁棒性，在如此复杂的场景中提供了令人满意的结果。这表明，这些模型可以成功应用于基于目标关键词替换的操控，如假新闻的生成或身份验证中冒充说话者。

## VII. 基准测试——数据稀缺场景

新的DeepFake生成方法不断被引入。以下基准测试针对数据量显著减少的情况下进行了训练。这种场景反映了以下情况：当新的DeepFake操作发布时，但没有其生成过程的访问权限，或者在使用消费者级PC进行内部验证时。在这种情况下，检测方法必须依赖收集的样本，而这些样本的数量通常比标准情况下的数据集要少得多。

该基准测试基于第IV节中描述的基准测试进行。在训练过程中，所用数据量减少至原训练和测试子集的10%。此外，为了防止在较小的数据集上过拟合，我们将训练epoch数从原来的10减少到4。需要注意的是，评估测试仍使用完整的数据集，因为攻击者在使用自己的攻击时不受限制，因此我们认为完整的评估更具代表性。

表VII显示了与完整数据集相比，各种解决方案的性能下降。尽管如此，LCNN和SpecRNet在训练数据减少10倍的情况下依然提供了可接受的性能——分别达到了0.6305和0.7997的EER，以及99.9599和99.9390的AUC。

另一方面，RawNet2的性能较弱，EER为24.0821，AUC为84.3158。这主要是因为其网络规模较大——该架构包含超过1700万个参数，需要更多的训练样本才能实现良好的泛化能力。

尽管如此，LCNN和SpecRNet的结果表明它们对小规模数据具有较好的鲁棒性，并显示出优良的泛化能力——仅使用10%的样本量就足以捕捉区分真实语音和生成语音的底层特征。这也表明，针对DeepFake检测的新数据集应更加注重生成方法的数量和多样性，而非样本量的单纯增加。

第VII节和第VI节中的基准测试分别在减少数据量至10%和25%的情况下运行，这些设置中包含的信息有所不同。RawNet2在较短语音片段场景中的EER表现优于数据稀缺场景。这可能是由于其模型参数数量的限制——90%数据的减少导致样本量不足，无法实现良好的泛化能力。另一方面，在数据稀缺场景中，LCNN和SpecRNet的EER结果更佳，但其差异没有RawNet2那么显著。由此我们得出结论，对于LCNN和SpecRNet，数据集中的样本量是足够泛化的。而短语音片段平均包含75%更少的伪造特征，这降低了模型性能。

## VIII. 结论与未来工作

在本研究中，我们针对音频DeepFake检测任务改进了时间性能。我们的主要贡献是提出了新的神经网络架构——SpecRNet。尽管显著降低了计算需求，该模型仍然能够实现与当前先进模型相当的结果。我们的方法应用范围广泛，包括处理在线视频平台中大量的视听材料，以及为普通用户提供解决方案，使其能够使用个人设备自行验证内容。

SpecRNet是一种基于频谱图音频表示的新型架构，受RawNet2启发。与最快速的DeepFake检测方法之一LCNN相比，我们的模型在推理速度方面提升了约40%，且检测结果相当。在基本基准测试中，SpecRNet的AUC仅比LCNN低0.0001%，而在数据减少的测试中（样本缩短或样本量减少），结果差异未超过0.002%。我们的比较包括在WaveFake音频DeepFake数据集上的SpecRNet、RawNet2和LCNN网络。

此外，我们验证了上述架构在三种新场景下的鲁棒性——有限攻击、短语音片段和小样本量训练数据。第一种场景提供了关于DeepFake生成方法对检测任务难度（性能）的更深刻见解；后两种场景则是评估模型在更复杂场景下表现的新方式——分别是关键词替换（短语音片段）和小数据集训练。这些测试在针对特定目标（如关键短语或密码）的攻击、缺乏用于标准训练的攻击数据（如新攻击）以及用户自行验证样本（受限于消费者级PC的限制）时，具有重要意义。此外，这种检测程序可用于内容提供平台，无论是快速预筛选方法（当数据量过大无法完全验证时），还是在训练集和测试集不平衡（如第VII节）时的情况下。尽管在更具挑战性的场景下性能有所下降，但我们的架构仍提供了令人满意的性能。

未来工作应着眼于提高模型性能并评估其泛化能力。此外，可以进一步研究专门针对利用短语嵌入完整句子的说话人识别系统（如参考文献[36]-[38]）。为进一步优化网络性能，可以利用其他前端特征（例如Mel频率倒谱系数，MFCC）或这些特征的组合，这已被证明能提供更好的稳定性和泛化能力（参考文献[23]）。
 泛化能力还可以在其他现有的音频DeepFake数据集（如ASVspoof2021和FakeAVCeleb）或它们的组合——Attack Agnostic Dataset（参考文献[23]）上进行评估。由于采用了不同攻击方法并分布于不同数据集折叠中，Attack Agnostic Dataset可提供模型面对新DeepFake生成算法时潜在性能的良好概览，这种方法易于扩展，适用于新数据集。